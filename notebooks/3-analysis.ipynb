{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10407118,"sourceType":"datasetVersion","datasetId":6449222},{"sourceId":10506418,"sourceType":"datasetVersion","datasetId":6504255}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 3. Data Analysis\n**Group Project for DATA INFORMATION AND QUALITY (2024-2025)** <br>\nAnalysis of Milan Personal Services - Database 12 <br>\nMauro Orazio Drago, Dennis Pierantozzi, Davide Morelli\n\nThe project requests to choose a type of analysis to perform on both the dirty and clean datasets to assess the quality of the data preparation pipeline developed in the previous steps. <br>\n\nWe have decided to focus on a **classification task for the \"Tipo esercizio pa\" column**, aiming to predict its value based on the other available data.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.300127Z","iopub.execute_input":"2025-01-18T14:18:10.300569Z","iopub.status.idle":"2025-01-18T14:18:10.305152Z","shell.execute_reply.started":"2025-01-18T14:18:10.300539Z","shell.execute_reply":"2025-01-18T14:18:10.304057Z"}},"outputs":[],"execution_count":154},{"cell_type":"markdown","source":"## Set up\nBelow the dataset dirty and the cleaned one have been imported.","metadata":{}},{"cell_type":"code","source":"SERVICES = pd.read_csv('/kaggle/input/servizi/Comune-di-Milano-Servizi-alla-persona-parrucchieri-estetisti.csv',sep=';',encoding='unicode_escape')\nSERVICES.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.323082Z","iopub.execute_input":"2025-01-18T14:18:10.323477Z","iopub.status.idle":"2025-01-18T14:18:10.359144Z","shell.execute_reply.started":"2025-01-18T14:18:10.323446Z","shell.execute_reply":"2025-01-18T14:18:10.358135Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"  Tipo esercizio pa                           Ubicazione Tipo via  \\\n0               NaN     LGO DEI GELSOMINI N. 10 (z.d. 6)      LGO   \n1               NaN              PZA FIDIA N. 3 (z.d. 9)      PZA   \n2               NaN             VIA ADIGE N. 10 (z.d. 5)      VIA   \n3               NaN  VIA BARACCHINI FLAVIO N. 9 (z.d. 1)      VIA   \n4               NaN           VIA BERGAMO N. 12 (z.d. 4)      VIA   \n\n                 Via Civico  Codice via ZD  \\\n0      DEI GELSOMINI     10      5394.0  6   \n1              FIDIA      3      1144.0  9   \n2              ADIGE     10      4216.0  5   \n3  BARACCHINI FLAVIO      9       356.0  1   \n4            BERGAMO     12      3189.0  4   \n\n                                Prevalente  Superficie altri usi  \\\n0                                      NaN                   NaN   \n1  CENTRO MASSAGGI RILASSANTI NON ESTETICI                   2.0   \n2                         CENTRO BENESSERE                   2.0   \n3                    TRUCCO SEMIPERMANENTE                   NaN   \n4                                      NaN                   NaN   \n\n   Superficie lavorativa  \n0                   55.0  \n1                   28.0  \n2                   27.0  \n3                    NaN  \n4                   50.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tipo esercizio pa</th>\n      <th>Ubicazione</th>\n      <th>Tipo via</th>\n      <th>Via</th>\n      <th>Civico</th>\n      <th>Codice via</th>\n      <th>ZD</th>\n      <th>Prevalente</th>\n      <th>Superficie altri usi</th>\n      <th>Superficie lavorativa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>LGO DEI GELSOMINI N. 10 (z.d. 6)</td>\n      <td>LGO</td>\n      <td>DEI GELSOMINI</td>\n      <td>10</td>\n      <td>5394.0</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>55.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>PZA FIDIA N. 3 (z.d. 9)</td>\n      <td>PZA</td>\n      <td>FIDIA</td>\n      <td>3</td>\n      <td>1144.0</td>\n      <td>9</td>\n      <td>CENTRO MASSAGGI RILASSANTI NON ESTETICI</td>\n      <td>2.0</td>\n      <td>28.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>VIA ADIGE N. 10 (z.d. 5)</td>\n      <td>VIA</td>\n      <td>ADIGE</td>\n      <td>10</td>\n      <td>4216.0</td>\n      <td>5</td>\n      <td>CENTRO BENESSERE</td>\n      <td>2.0</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>VIA BARACCHINI FLAVIO N. 9 (z.d. 1)</td>\n      <td>VIA</td>\n      <td>BARACCHINI FLAVIO</td>\n      <td>9</td>\n      <td>356.0</td>\n      <td>1</td>\n      <td>TRUCCO SEMIPERMANENTE</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>VIA BERGAMO N. 12 (z.d. 4)</td>\n      <td>VIA</td>\n      <td>BERGAMO</td>\n      <td>12</td>\n      <td>3189.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":155},{"cell_type":"code","source":"SERVICES_CLEANED = pd.read_csv('/kaggle/input/cleaned-services/cleaned-SERVICES.csv', index_col=False)\nSERVICES_CLEANED = SERVICES_CLEANED.drop(columns=[\"Unnamed: 0\"])\nSERVICES_CLEANED.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.360387Z","iopub.execute_input":"2025-01-18T14:18:10.360659Z","iopub.status.idle":"2025-01-18T14:18:10.380619Z","shell.execute_reply.started":"2025-01-18T14:18:10.360637Z","shell.execute_reply":"2025-01-18T14:18:10.379703Z"}},"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"                                                t_es   t_via  \\\n0                          Tipo A - Estetica Manuale  Piazza   \n1  Tipo B - Centro di Abbronzatura;Tipo A - Estet...   Corso   \n2   Tipo A - Estetica Manuale;Parrucchiere per Donna   Corso   \n3                                       Acconciatore   Corso   \n4                             Parrucchiere per Donna   Corso   \n\n                  via  civ  cod_via  zd  sup_alt  sup_lav  \n0           DEL DUOMO   17        1   1      6.0     74.0  \n1  GIUSEPPE GARIBALDI  104     1010   1     27.0     49.0  \n2  GIUSEPPE GARIBALDI  110     1010   1     17.0     88.0  \n3  GIUSEPPE GARIBALDI   39     1010   1      6.0     54.0  \n4  GIUSEPPE GARIBALDI   46     1010   1      4.0     31.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_es</th>\n      <th>t_via</th>\n      <th>via</th>\n      <th>civ</th>\n      <th>cod_via</th>\n      <th>zd</th>\n      <th>sup_alt</th>\n      <th>sup_lav</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tipo A - Estetica Manuale</td>\n      <td>Piazza</td>\n      <td>DEL DUOMO</td>\n      <td>17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6.0</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tipo B - Centro di Abbronzatura;Tipo A - Estet...</td>\n      <td>Corso</td>\n      <td>GIUSEPPE GARIBALDI</td>\n      <td>104</td>\n      <td>1010</td>\n      <td>1</td>\n      <td>27.0</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Tipo A - Estetica Manuale;Parrucchiere per Donna</td>\n      <td>Corso</td>\n      <td>GIUSEPPE GARIBALDI</td>\n      <td>110</td>\n      <td>1010</td>\n      <td>1</td>\n      <td>17.0</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Acconciatore</td>\n      <td>Corso</td>\n      <td>GIUSEPPE GARIBALDI</td>\n      <td>39</td>\n      <td>1010</td>\n      <td>1</td>\n      <td>6.0</td>\n      <td>54.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Parrucchiere per Donna</td>\n      <td>Corso</td>\n      <td>GIUSEPPE GARIBALDI</td>\n      <td>46</td>\n      <td>1010</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>31.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":156},{"cell_type":"markdown","source":"## Dirty Dataset Pipeline\n\nFirst of all we have identified the features we wanted to use for our task. <br>\nFeatures we are going to use:\n* Tipo esercizio pa\n* Tipo via\n* Via\n* ZD\n* Superficie altri usi\n* Superficie lavorativa","metadata":{}},{"cell_type":"code","source":"SERVICES = SERVICES.drop(columns=[\"Civico\", \"Via\", \"Prevalente\", \"Ubicazione\", \"Codice via\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.382344Z","iopub.execute_input":"2025-01-18T14:18:10.382684Z","iopub.status.idle":"2025-01-18T14:18:10.387708Z","shell.execute_reply.started":"2025-01-18T14:18:10.382655Z","shell.execute_reply":"2025-01-18T14:18:10.386756Z"}},"outputs":[],"execution_count":157},{"cell_type":"markdown","source":"From the first assessment we have made we know that the the dirty dataset contains a lot of null values and categorical values. <br>\nWe need to handle the missing values and encode the categorical features to make them suitable for the training phase.","metadata":{}},{"cell_type":"code","source":"SERVICES.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.389125Z","iopub.execute_input":"2025-01-18T14:18:10.389477Z","iopub.status.idle":"2025-01-18T14:18:10.396210Z","shell.execute_reply.started":"2025-01-18T14:18:10.389449Z","shell.execute_reply":"2025-01-18T14:18:10.395047Z"}},"outputs":[{"execution_count":158,"output_type":"execute_result","data":{"text/plain":"Tipo esercizio pa         object\nTipo via                  object\nZD                        object\nSuperficie altri usi     float64\nSuperficie lavorativa    float64\ndtype: object"},"metadata":{}}],"execution_count":158},{"cell_type":"code","source":"null_count = SERVICES.isnull().sum()\nprint('Number of null values:\\n', null_count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.397215Z","iopub.execute_input":"2025-01-18T14:18:10.397548Z","iopub.status.idle":"2025-01-18T14:18:10.404216Z","shell.execute_reply.started":"2025-01-18T14:18:10.397523Z","shell.execute_reply":"2025-01-18T14:18:10.403274Z"}},"outputs":[{"name":"stdout","text":"Number of null values:\n Tipo esercizio pa          31\nTipo via                    1\nZD                          1\nSuperficie altri usi     3164\nSuperficie lavorativa    1308\ndtype: int64\n","output_type":"stream"}],"execution_count":159},{"cell_type":"markdown","source":"### Handling null values\nFor the values in \"Superficie lavorativa\" and \"Superficie altri usi\" we have filled the null values with the median of the values to keep the same idea used in our data cleaning phase.\n\n* \"Tipo esercizio pa\" null values are dropped\n* \"Superficie lavorativa\" filled with the median of the values\n* \"Superficie altri usi\" filled with the median of the values","metadata":{}},{"cell_type":"code","source":"# Step 2: Replace missing values in \"superficie lavorativa\" with the median\nmedian_superficie = SERVICES[\"Superficie lavorativa\"].median(skipna=True)\nmedian_superficie_altri_usi = SERVICES[\"Superficie altri usi\"].median(skipna=True)\n\nSERVICES[\"Superficie lavorativa\"] = SERVICES[\"Superficie lavorativa\"].fillna(median_superficie)\nSERVICES[\"Superficie altri usi\"] = SERVICES[\"Superficie altri usi\"].fillna(median_superficie)\n\nSERVICES = SERVICES.dropna(subset=[\"Tipo esercizio pa\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.405599Z","iopub.execute_input":"2025-01-18T14:18:10.405900Z","iopub.status.idle":"2025-01-18T14:18:10.415417Z","shell.execute_reply.started":"2025-01-18T14:18:10.405865Z","shell.execute_reply":"2025-01-18T14:18:10.414453Z"}},"outputs":[],"execution_count":160},{"cell_type":"markdown","source":"### Encoding\nSince the \"Tipo esercizio pa\" has 103 unique values we have decided to perform a Label Encoding instead of a One-Hot Encoding technique.<br>\n\n* Tipo esercizio pa: encoding used LabelEncoder of sklearn\n* Tipo via: one hot encoding\n* ZD: one hot encoding","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\nSERVICES[\"tipo_esercizio_encoded\"] = label_encoder.fit_transform(SERVICES[\"Tipo esercizio pa\"])\n\n# Count occurrences of each class\nclass_counts = SERVICES[\"tipo_esercizio_encoded\"].value_counts()\n\n# Filter out classes with only one instance\nSERVICES = SERVICES[SERVICES[\"tipo_esercizio_encoded\"].isin(class_counts[class_counts > 1].index)]\n\n# Re-encode the labels after filtering\nlabel_encoder = LabelEncoder()\nSERVICES[\"tipo_esercizio_encoded\"] = label_encoder.fit_transform(SERVICES[\"tipo_esercizio_encoded\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.416627Z","iopub.execute_input":"2025-01-18T14:18:10.416921Z","iopub.status.idle":"2025-01-18T14:18:10.426537Z","shell.execute_reply.started":"2025-01-18T14:18:10.416893Z","shell.execute_reply":"2025-01-18T14:18:10.425580Z"}},"outputs":[],"execution_count":161},{"cell_type":"code","source":"print(class_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.428139Z","iopub.execute_input":"2025-01-18T14:18:10.428462Z","iopub.status.idle":"2025-01-18T14:18:10.433516Z","shell.execute_reply.started":"2025-01-18T14:18:10.428437Z","shell.execute_reply":"2025-01-18T14:18:10.432519Z"}},"outputs":[{"name":"stdout","text":"tipo_esercizio_encoded\n26     1048\n1       586\n43      439\n69      335\n75      313\n       ... \n91        1\n90        1\n92        1\n80        1\n101       1\nName: count, Length: 103, dtype: int64\n","output_type":"stream"}],"execution_count":162},{"cell_type":"code","source":"SERVICES = pd.get_dummies(SERVICES, columns=[\"Tipo via\"], prefix=\"tipo_via\", drop_first=True)\nSERVICES = pd.get_dummies(SERVICES, columns=[\"ZD\"], prefix=\"zd\", drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.434695Z","iopub.execute_input":"2025-01-18T14:18:10.434966Z","iopub.status.idle":"2025-01-18T14:18:10.445894Z","shell.execute_reply.started":"2025-01-18T14:18:10.434945Z","shell.execute_reply":"2025-01-18T14:18:10.445072Z"}},"outputs":[],"execution_count":163},{"cell_type":"code","source":"SERVICES.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.446870Z","iopub.execute_input":"2025-01-18T14:18:10.447230Z","iopub.status.idle":"2025-01-18T14:18:10.468108Z","shell.execute_reply.started":"2025-01-18T14:18:10.447178Z","shell.execute_reply":"2025-01-18T14:18:10.466950Z"}},"outputs":[{"execution_count":164,"output_type":"execute_result","data":{"text/plain":"   Tipo esercizio pa  Superficie altri usi  Superficie lavorativa  \\\n31      Acconciatore                  34.0                   68.0   \n32      Acconciatore                  34.0                   34.0   \n34      Acconciatore                  34.0                   34.0   \n35      Acconciatore                  34.0                   25.0   \n36      Acconciatore                  34.0                   28.0   \n\n    tipo_esercizio_encoded  tipo_via_BST  tipo_via_CSO  tipo_via_FOR  \\\n31                       5         False          True         False   \n32                       5         False         False         False   \n34                       5         False          True         False   \n35                       5         False          True         False   \n36                       5         False          True         False   \n\n    tipo_via_GLL  tipo_via_LGO  tipo_via_PAS  ...  tipo_via_VLE  tipo_via_VLO  \\\n31         False         False         False  ...         False         False   \n32         False         False         False  ...         False         False   \n34         False         False         False  ...         False         False   \n35         False         False         False  ...         False         False   \n36         False         False         False  ...         False         False   \n\n     zd_2   zd_3   zd_4   zd_5   zd_6   zd_7   zd_8   zd_9  \n31  False   True  False  False  False  False  False  False  \n32  False  False  False  False  False  False  False  False  \n34  False  False  False  False  False  False  False  False  \n35  False  False  False  False  False  False  False  False  \n36  False  False  False  False  False  False  False  False  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tipo esercizio pa</th>\n      <th>Superficie altri usi</th>\n      <th>Superficie lavorativa</th>\n      <th>tipo_esercizio_encoded</th>\n      <th>tipo_via_BST</th>\n      <th>tipo_via_CSO</th>\n      <th>tipo_via_FOR</th>\n      <th>tipo_via_GLL</th>\n      <th>tipo_via_LGO</th>\n      <th>tipo_via_PAS</th>\n      <th>...</th>\n      <th>tipo_via_VLE</th>\n      <th>tipo_via_VLO</th>\n      <th>zd_2</th>\n      <th>zd_3</th>\n      <th>zd_4</th>\n      <th>zd_5</th>\n      <th>zd_6</th>\n      <th>zd_7</th>\n      <th>zd_8</th>\n      <th>zd_9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31</th>\n      <td>Acconciatore</td>\n      <td>34.0</td>\n      <td>68.0</td>\n      <td>5</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Acconciatore</td>\n      <td>34.0</td>\n      <td>34.0</td>\n      <td>5</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Acconciatore</td>\n      <td>34.0</td>\n      <td>34.0</td>\n      <td>5</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Acconciatore</td>\n      <td>34.0</td>\n      <td>25.0</td>\n      <td>5</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Acconciatore</td>\n      <td>34.0</td>\n      <td>28.0</td>\n      <td>5</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":164},{"cell_type":"markdown","source":"### Model Selection\nThe dataset has been splitted in train (80%) and test (20%). <br>\nWe have used a **Random Forest Classification** from the sklearn library.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\nX = SERVICES.drop(columns=['tipo_esercizio_encoded', 'Tipo esercizio pa'])  # Drop the target column\ny = SERVICES['tipo_esercizio_encoded']  # Target is the encoded 'tipo esercizio'\n\n# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Initialize the classifier (RandomForest in this case)\nclassifier = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nclassifier.fit(X_train, y_train)\n\n# Make predictions\ny_pred = classifier.predict(X_test)\n\naccuracy_rf_dirty = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred, output_dict=True)\n\n# Extract overall precision, recall, and F1-score from the 'weighted avg' section\nprecision_rf_dirty = report['weighted avg']['precision']\nrecall_rf_dirty = report['weighted avg']['recall']\nf1_score_rf_dirty = report['weighted avg']['f1-score']\n\n# Print the results\nprint(f\"Accuracy: {accuracy_rf_dirty:.4f}\")\nprint(f\"Precision: {precision_rf_dirty:.4f}\")\nprint(f\"Recall: {recall_rf_dirty:.4f}\")\nprint(f\"F1 Score: {f1_score_rf_dirty:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:10.470040Z","iopub.execute_input":"2025-01-18T14:18:10.470462Z","iopub.status.idle":"2025-01-18T14:18:11.033938Z","shell.execute_reply.started":"2025-01-18T14:18:10.470423Z","shell.execute_reply":"2025-01-18T14:18:11.032899Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.1966\nPrecision: 0.1637\nRecall: 0.1966\nF1 Score: 0.1769\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":165},{"cell_type":"code","source":"# Initialize the classifier (RandomForest in this case)\nxgb_classifier = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n\n# Train the model\nxgb_classifier.fit(X_train, y_train)\n\n# Make predictions\ny_pred = xgb_classifier.predict(X_test)\n\naccuracy_xgb_dirty = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred, output_dict=True)\n\n# Extract overall precision, recall, and F1-score from the 'weighted avg' section\nprecision_xgb_dirty = report['weighted avg']['precision']\nrecall_xgb_dirty = report['weighted avg']['recall']\nf1_score_xgb_dirty = report['weighted avg']['f1-score']\n\n# Print the results\nprint(f\"Accuracy: {accuracy_xgb_dirty:.4f}\")\nprint(f\"Precision: {precision_xgb_dirty:.4f}\")\nprint(f\"Recall: {recall_xgb_dirty:.4f}\")\nprint(f\"F1 Score: {f1_score_xgb_dirty:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:11.035183Z","iopub.execute_input":"2025-01-18T14:18:11.035503Z","iopub.status.idle":"2025-01-18T14:18:13.743473Z","shell.execute_reply.started":"2025-01-18T14:18:11.035477Z","shell.execute_reply":"2025-01-18T14:18:13.742426Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.2474\nPrecision: 0.2087\nRecall: 0.2474\nF1 Score: 0.2111\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":166},{"cell_type":"markdown","source":"## Clean Dataset Pipeline\nFor the cleaned dataset we have performed the same steps as did for the dirty dataset but in this case there is no need to handle null values. <br>\nFeatures we have selected:\n* t_es\n* t_via\n* zd\n* sup_alt\n* sup_lav","metadata":{}},{"cell_type":"code","source":"# The cleaned dataset doesn't have null values\nnull_count = SERVICES_CLEANED.isnull().sum()\nprint('Number of null values:\\n', null_count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:13.744625Z","iopub.execute_input":"2025-01-18T14:18:13.744889Z","iopub.status.idle":"2025-01-18T14:18:13.751807Z","shell.execute_reply.started":"2025-01-18T14:18:13.744868Z","shell.execute_reply":"2025-01-18T14:18:13.750806Z"}},"outputs":[{"name":"stdout","text":"Number of null values:\n t_es       0\nt_via      0\nvia        0\nciv        0\ncod_via    0\nzd         0\nsup_alt    0\nsup_lav    0\ndtype: int64\n","output_type":"stream"}],"execution_count":167},{"cell_type":"code","source":"# Drop the unselected features\nSERVICES_CLEANED = SERVICES_CLEANED.drop(columns=[\"civ\", \"via\", \"cod_via\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:13.752556Z","iopub.execute_input":"2025-01-18T14:18:13.752822Z","iopub.status.idle":"2025-01-18T14:18:13.757440Z","shell.execute_reply.started":"2025-01-18T14:18:13.752799Z","shell.execute_reply":"2025-01-18T14:18:13.756456Z"}},"outputs":[],"execution_count":168},{"cell_type":"markdown","source":"### Encoding\nWe have encoded the \"t_es\", \"t_via\", \"zd\" as did for the columns \"Tipo esercizio pa\", \"Tipo via\", \"Zd\" of the dirty dataset respectively.","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\nSERVICES_CLEANED[\"t_es_encoded\"] = label_encoder.fit_transform(SERVICES_CLEANED[\"t_es\"])\n\n# Display the first few rows to confirm changes\nSERVICES_CLEANED.t_es_encoded.unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:13.759571Z","iopub.execute_input":"2025-01-18T14:18:13.759829Z","iopub.status.idle":"2025-01-18T14:18:13.767650Z","shell.execute_reply.started":"2025-01-18T14:18:13.759807Z","shell.execute_reply":"2025-01-18T14:18:13.766812Z"}},"outputs":[{"execution_count":169,"output_type":"execute_result","data":{"text/plain":"array([19, 24, 22,  0,  8, 20, 11, 25, 12, 30, 29, 27, 16, 21, 26,  3, 32,\n       13, 28, 10,  6,  5,  1, 14,  2, 23,  7, 15,  4, 18, 31,  9, 17])"},"metadata":{}}],"execution_count":169},{"cell_type":"code","source":"SERVICES_CLEANED = pd.get_dummies(SERVICES_CLEANED, columns=[\"t_via\"], prefix=\"t_via\", drop_first=True)\nSERVICES_CLEANED = pd.get_dummies(SERVICES_CLEANED, columns=[\"zd\"], prefix=\"zd\", drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:13.768699Z","iopub.execute_input":"2025-01-18T14:18:13.768966Z","iopub.status.idle":"2025-01-18T14:18:13.778450Z","shell.execute_reply.started":"2025-01-18T14:18:13.768937Z","shell.execute_reply":"2025-01-18T14:18:13.777589Z"}},"outputs":[],"execution_count":170},{"cell_type":"markdown","source":"### Model Selection\nThe dataset has been splitted with the same ratio used for the dirty dataset: 80% training, 20% test. <br>\nWe have tried Random Forest as did for the dirty dataset. <br>\n\nThen we have also tried XGBoost Classifier to improve the accuracy further.","metadata":{}},{"cell_type":"code","source":"X = SERVICES_CLEANED.drop(columns=['t_es_encoded', 't_es'])  # Drop the target column\ny = SERVICES_CLEANED['t_es_encoded']  # Target is the encoded 'tipo esercizio'\n\n# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:13.779339Z","iopub.execute_input":"2025-01-18T14:18:13.779593Z","iopub.status.idle":"2025-01-18T14:18:13.786952Z","shell.execute_reply.started":"2025-01-18T14:18:13.779572Z","shell.execute_reply":"2025-01-18T14:18:13.786132Z"}},"outputs":[],"execution_count":171},{"cell_type":"code","source":"# Random Forest Classifier\n\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_classifier.fit(X_train, y_train)\n\n# Make predictions\ny_pred = rf_classifier.predict(X_test)\n\naccuracy_rf_clean = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred, output_dict=True)\n\n# Extract overall precision, recall, and F1-score from the 'weighted avg' section\nprecision_rf_clean = report['weighted avg']['precision']\nrecall_rf_clean = report['weighted avg']['recall']\nf1_score_rf_clean = report['weighted avg']['f1-score']\n\n# Print the results\nprint(f\"Accuracy: {accuracy_rf_clean:.4f}\")\nprint(f\"Precision: {precision_rf_clean:.4f}\")\nprint(f\"Recall: {recall_rf_clean:.4f}\")\nprint(f\"F1 Score: {f1_score_rf_clean:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:13.787988Z","iopub.execute_input":"2025-01-18T14:18:13.788307Z","iopub.status.idle":"2025-01-18T14:18:14.235654Z","shell.execute_reply.started":"2025-01-18T14:18:13.788273Z","shell.execute_reply":"2025-01-18T14:18:14.234606Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.6657\nPrecision: 0.6529\nRecall: 0.6657\nF1 Score: 0.6568\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":172},{"cell_type":"code","source":"# XGB Classifier\n\nxgb_classifier = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n\nxgb_classifier.fit(X_train, y_train)\n\n# Make predictions\ny_pred = xgb_classifier.predict(X_test)\n\naccuracy_xgb_clean = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred, output_dict=True)\n\n# Extract overall precision, recall, and F1-score from the 'weighted avg' section\nprecision_xgb_clean = report['weighted avg']['precision']\nrecall_xgb_clean = report['weighted avg']['recall']\nf1_score_xgb_clean = report['weighted avg']['f1-score']\n\n# Print the results\nprint(f\"Accuracy: {accuracy_xgb_clean:.4f}\")\nprint(f\"Precision: {precision_xgb_clean:.4f}\")\nprint(f\"Recall: {recall_xgb_clean:.4f}\")\nprint(f\"F1 Score: {f1_score_xgb_clean:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:18:14.236720Z","iopub.execute_input":"2025-01-18T14:18:14.237118Z","iopub.status.idle":"2025-01-18T14:18:15.477442Z","shell.execute_reply.started":"2025-01-18T14:18:14.237081Z","shell.execute_reply":"2025-01-18T14:18:15.476145Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7570\nPrecision: 0.7579\nRecall: 0.7570\nF1 Score: 0.7525\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":173},{"cell_type":"markdown","source":"## Conclusions\nForm our analysis for the classification task we have obtained the following results:\n","metadata":{}},{"cell_type":"code","source":"results = {\n    \"Model-Dataset\": [\n        \"RandomForest-DatasetDirty\",\n        \"RandomForest-DatasetCleaned\",\n        \"XGB-DatasetDirty\",\n        \"XGB-DatasetCleaned\"\n    ],\n    \"Accuracy\": [accuracy_rf_dirty, accuracy_rf_clean, accuracy_xgb_dirty, accuracy_xgb_clean],\n    \"Precision\": [precision_rf_dirty, precision_rf_clean, precision_xgb_dirty, precision_xgb_clean],\n    \"Recall\": [recall_rf_dirty, recall_rf_clean, recall_xgb_dirty, recall_xgb_clean],\n    \"F1 Score\": [f1_score_rf_dirty, f1_score_rf_clean, f1_score_xgb_dirty, f1_score_xgb_clean]\n}\n\n# Create the DataFrame\nresults_df = pd.DataFrame(results)\n\n# Print the reordered table\nprint(results_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:23:21.974341Z","iopub.execute_input":"2025-01-18T14:23:21.974815Z","iopub.status.idle":"2025-01-18T14:23:21.989914Z","shell.execute_reply.started":"2025-01-18T14:23:21.974779Z","shell.execute_reply":"2025-01-18T14:23:21.988759Z"}},"outputs":[{"name":"stdout","text":"                 Model-Dataset  Accuracy  Precision    Recall  F1 Score\n0    RandomForest-DatasetDirty  0.196615   0.163688  0.196615  0.176864\n1  RandomForest-DatasetCleaned  0.665685   0.652894  0.665685  0.656759\n2             XGB-DatasetDirty  0.247396   0.208719  0.247396  0.211121\n3           XGB-DatasetCleaned  0.756996   0.757881  0.756996  0.752541\n","output_type":"stream"}],"execution_count":182},{"cell_type":"markdown","source":"**Our conclusions:**\n\n* The cleaned dataset significantly improves the performance of both models, particularly for XGBoost, which performs best when the data is well-prepared. The dirty dataset severely hampers model performance, especially for RandomForest.\n* On both cleaned and dirty datasets, XGBoost outperforms RandomForest in terms of all metrics. This suggests that XGBoost is a more robust algorithm, especially when dealing with noisy or unclean data.","metadata":{}}]}